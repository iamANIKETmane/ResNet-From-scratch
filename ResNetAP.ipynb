{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "#from torchsummary.torchsummary import summary\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def dataloader_cifar():\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load CIFAR-10 training data from local directory\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root='/Users/aniketmane/Desktop/sem-2/DL/Project1/deep-learning-spring-2025-project-1/cifar-10-python',\n",
    "        train=True,\n",
    "        download=False,  # Set to False since data is already present\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # Split into training and validation sets (45000/5000)\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [45000, 5000])\n",
    "\n",
    "    # Load CUSTOM TEST DATA (replace with your custom test data path)\n",
    "    # Example: Custom test data stored in a file called 'custom_test_batch'\n",
    "    test_dict = unpickle('/Users/aniketmane/Desktop/sem-2/DL/Project1/deep-learning-spring-2025-project-1/cifar-10-python/custom_test_batch')\n",
    "    test_data = test_dict[b'data']  # Shape: [N, 3072]\n",
    "    test_ids = test_dict[b'ids']    # List of N sample IDs\n",
    "\n",
    "    # Convert test data to PyTorch Dataset\n",
    "    class CustomTestDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, data, ids, transform=None):\n",
    "            self.data = data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Reshape to [N, 32, 32, 3]\n",
    "            self.ids = ids\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.ids)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.data[idx]\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, self.ids[idx]\n",
    "\n",
    "    test_dataset = CustomTestDataset(test_data, test_ids, transform=transform)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    BATCH_SIZE = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines a Lambda Layer. It allows to perform arbitrary operations specified by the \"lambd\" argument.\n",
    "\n",
    "    Attributes:\n",
    "        lambd: a function that defines the operation to be performed on the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lambd):\n",
    "        \"\"\"\n",
    "        Init method for the Lambda Layer.\n",
    "\n",
    "        Args:\n",
    "            lambd (function): Function that defines the operation to be performed on the input.\n",
    "        \"\"\"\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Lambda Layer. It applies the function to the input.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to the Lambda Layer.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output of the Lambda Layer after applying the function.\n",
    "        \"\"\"\n",
    "        return self.lambd(x)\n",
    "\n",
    "class BasicConvBlock(nn.Module):\n",
    "    \n",
    "    ''' The BasicConvBlock takes an input with in_channels, applies some blocks of convolutional layers \n",
    "    to reduce it to out_channels and sum it up to the original input. \n",
    "    If their sizes mismatch, then the input goes into an identity. \n",
    "    \n",
    "    Basically The BasicConvBlock will implement the regular basic Conv Block + \n",
    "    the shortcut block that does the dimension matching job (option A or B) when dimension changes between 2 blocks\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, option='A'):\n",
    "        \"\"\"\n",
    "        Init method for the Basic Convolution Block.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of channels in the input tensor.\n",
    "            out_channels (int): Number of channels in the output tensor.\n",
    "            stride (int, optional): Stride for the convolution operation. Default is 1.\n",
    "            option (str, optional): Option for the shortcut connection to match dimensions. Default is 'A'.\n",
    "        \"\"\"\n",
    "        super(BasicConvBlock, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)),\n",
    "            ('bn1', nn.BatchNorm2d(out_channels)),\n",
    "            ('act1', nn.ReLU()),\n",
    "            ('conv2', nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn2', nn.BatchNorm2d(out_channels))\n",
    "        ]))\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        '''  When input and output spatial dimensions don't match, we have 2 options, with stride:\n",
    "            - A) Use identity shortcuts with zero padding to increase channel dimension.    \n",
    "            - B) Use 1x1 convolution to increase channel dimension (projection shortcut).\n",
    "         '''\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            if option == 'A':\n",
    "                # Use identity shortcuts with zero padding to increase channel dimension.\n",
    "                pad_to_add = out_channels//4\n",
    "                ''' ::2 is doing the job of stride = 2\n",
    "                F.pad apply padding to (W,H,C,N).\n",
    "                \n",
    "                The padding lengths are specified in reverse order of the dimensions,\n",
    "                F.pad(x[:, :, ::2, ::2], (0,0, 0,0, pad,pad, 0,0))\n",
    "\n",
    "                [width_beginning, width_end, height_beginning, height_end, channel_beginning, channel_end, batchLength_beginning, batchLength_end ]\n",
    "\n",
    "                '''\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                            F.pad(x[:, :, ::2, ::2], (0,0, 0,0, pad_to_add, pad_to_add, 0,0)))\n",
    "            if option == 'B':\n",
    "                self.shortcut = nn.Sequential(OrderedDict([\n",
    "                    ('s_conv1', nn.Conv2d(in_channels, 2*out_channels, kernel_size=1, stride=stride, padding=0, bias=False)),\n",
    "                    ('s_bn1', nn.BatchNorm2d(2*out_channels))\n",
    "                ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Basic Convolution Block. It applies the sequence of layers and adds the shortcut connection.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to the Basic Convolution Block.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output of the Basic Convolution Block.\n",
    "        \"\"\"\n",
    "        out = self.features(x)\n",
    "        # sum it up with shortcut layer\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\" ResNet-56 architecture for CIFAR-10 Dataset of shape 32*32*3.\n",
    "    \n",
    "    Args:\n",
    "        block_type (nn.Module): The type of residual block to use.\n",
    "        num_blocks (list): List containing the number of blocks for each layer.\n",
    "    \n",
    "    Attributes:\n",
    "        in_channels (int): Number of input channels.\n",
    "        conv0 (nn.Conv2d): Initial convolutional layer.\n",
    "        bn0 (nn.BatchNorm2d): Batch normalization layer.\n",
    "        block1 (nn.Sequential): First block layer.\n",
    "        block2 (nn.Sequential): Second block layer.\n",
    "        block3 (nn.Sequential): Third block layer.\n",
    "        avgpool (nn.AdaptiveAvgPool2d): Adaptive average pooling layer.\n",
    "        linear (nn.Linear): Linear layer for classification. \"\"\"\n",
    "    def __init__(self, block_type, num_blocks):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = 16\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn0 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.block1 = self.__build_layer(block_type, 16, num_blocks[0], starting_stride=1)\n",
    "        \n",
    "        self.block2 = self.__build_layer(block_type, 32, num_blocks[1], starting_stride=2)\n",
    "        \n",
    "        self.block3 = self.__build_layer(block_type, 64, num_blocks[2], starting_stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear = nn.Linear(64, 10)\n",
    "    \n",
    "    def __build_layer(self, block_type, out_channels, num_blocks, starting_stride):\n",
    "        \"\"\"\n",
    "        Build a layer consisting of multiple residual blocks.\n",
    "        \n",
    "        Args:\n",
    "            block_type (nn.Module): The type of residual block to use.\n",
    "            out_channels (int): Number of output channels.\n",
    "            num_blocks (int): Number of blocks in the layer.\n",
    "            starting_stride (int): Stride value for the first block.\n",
    "        \n",
    "        Returns:\n",
    "            nn.Sequential: Sequential container of the residual blocks.\n",
    "        \"\"\"\n",
    "        \n",
    "        strides_list_for_current_block = [starting_stride] + [1]*(num_blocks-1)\n",
    "        ''' Above line will generate an array whose first element is starting_stride\n",
    "        And it will have (num_blocks-1) more elements each of value 1\n",
    "         '''\n",
    "        # print('strides_list_for_current_block ', strides_list_for_current_block)\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        for stride in strides_list_for_current_block:\n",
    "            layers.append(block_type(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the ResNet model.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        out = F.relu(self.bn0(self.conv0(x)))\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)        \n",
    "        out = self.block3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet56():\n",
    "    return ResNet(block_type=BasicConvBlock, num_blocks=[9,9,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (block1): Sequential(\n",
       "    (0): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (6): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (7): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (8): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "    (1): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (6): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (7): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (8): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "    (1): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (6): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (7): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (8): BasicConvBlock(\n",
       "      (features): Sequential(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet56()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = 'cpu'\n",
    "model.to(device)\n",
    "#summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, ids, transform=None):\n",
    "        self.data = data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Shape [N, 32, 32, 3]\n",
    "        self.ids = ids\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_cifar():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Fixed for 3 channels\n",
    "    ])\n",
    "\n",
    "    # Load CIFAR-10 Training Data\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root='/Users/aniketmane/Desktop/sem-2/DL/Project1/deep-learning-spring-2025-project-1/cifar-10-python',\n",
    "        train=True,\n",
    "        download=False,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # Load CUSTOM TEST DATA (correct path)\n",
    "    test_dict = unpickle('/Users/aniketmane/Desktop/sem-2/DL/Project1/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl')  # Include filename\n",
    "    test_data = test_dict[b'data']\n",
    "    test_ids = test_dict[b'ids']\n",
    "    test_dataset = CustomTestDataset(test_data, test_ids, transform=transform)\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    train_dataset, val_dataset = random_split(train_dataset, (45000, 5000))\n",
    "\n",
    "    print(\"Image shape of a random sample image: {}\".format(train_dataset[0][0].shape))\n",
    "    print(\"Training Set: {} images\".format(len(train_dataset)))\n",
    "    print(\"Validation Set: {} images\".format(len(val_dataset)))\n",
    "    print(\"Test Set: {} images\".format(len(test_dataset)))\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape of a random sample image: torch.Size([3, 32, 32])\n",
      "Training Set: 45000 images\n",
      "Validation Set: 5000 images\n",
      "Test Set: 10000 images\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = dataloader_cifar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    EPOCHS = 30\n",
    "    train_samples_num = 45000\n",
    "    val_samples_num = 5000\n",
    "    train_costs, val_costs = [], []\n",
    "    \n",
    "    #Training phase.    \n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        train_running_loss = 0\n",
    "        correct_train = 0\n",
    "        \n",
    "        model.train().cuda()\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            \"\"\" for every mini-batch during the training phase, we typically want to explicitly set the gradients \n",
    "            to zero before starting to do backpropragation \"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Start the forward pass\n",
    "            prediction = model(inputs)\n",
    "                        \n",
    "            loss = criterion(prediction, labels)\n",
    "          \n",
    "            # do backpropagation and update weights with step()\n",
    "            loss.backward()         \n",
    "            optimizer.step()\n",
    "            \n",
    "            # print('outputs on which to apply torch.max ', prediction)\n",
    "            # find the maximum along the rows, use dim=1 to torch.max()\n",
    "            _, predicted_outputs = torch.max(prediction.data, 1)\n",
    "            \n",
    "            # Update the running corrects \n",
    "            correct_train += (predicted_outputs == labels).float().sum().item()\n",
    "            \n",
    "            ''' Compute batch loss\n",
    "            multiply each average batch loss with batch-length. \n",
    "            The batch-length is inputs.size(0) which gives the number total images in each batch. \n",
    "            Essentially I am un-averaging the previously calculated Loss '''\n",
    "            train_running_loss += (loss.data.item() * inputs.shape[0])\n",
    "\n",
    "\n",
    "        train_epoch_loss = train_running_loss / train_samples_num\n",
    "        \n",
    "        train_costs.append(train_epoch_loss)\n",
    "        \n",
    "        train_acc =  correct_train / train_samples_num\n",
    "\n",
    "        # Now check trained weights on the validation set\n",
    "        val_running_loss = 0\n",
    "        correct_val = 0\n",
    "      \n",
    "        model.eval().cuda()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass.\n",
    "                prediction = model(inputs)\n",
    "\n",
    "                # Compute the loss.\n",
    "                loss = criterion(prediction, labels)\n",
    "\n",
    "                # Compute validation accuracy.\n",
    "                _, predicted_outputs = torch.max(prediction.data, 1)\n",
    "                correct_val += (predicted_outputs == labels).float().sum().item()\n",
    "\n",
    "            # Compute batch loss.\n",
    "            val_running_loss += (loss.data.item() * inputs.shape[0])\n",
    "\n",
    "            val_epoch_loss = val_running_loss / val_samples_num\n",
    "            val_costs.append(val_epoch_loss)\n",
    "            val_acc =  correct_val / val_samples_num\n",
    "        \n",
    "        info = \"[Epoch {}/{}]: train-loss = {:0.6f} | train-acc = {:0.3f} | val-loss = {:0.6f} | val-acc = {:0.3f}\"\n",
    "        \n",
    "        print(info.format(epoch+1, EPOCHS, train_epoch_loss, train_acc, val_epoch_loss, val_acc))\n",
    "        \n",
    "        torch.save(model.state_dict(), '/content/checkpoint_gpu_{}'.format(epoch + 1)) \n",
    "                                                                \n",
    "    torch.save(model.state_dict(), '/content/resnet-56_weights_gpu')  \n",
    "        \n",
    "    return train_costs, val_costs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m test_samples_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m      2\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[0;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m  torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1050\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: t\u001b[38;5;241m.\u001b[39mcuda(device))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1050\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: t\u001b[38;5;241m.\u001b[39mcuda(device))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "test_samples_num = 10000\n",
    "correct = 0 \n",
    "\n",
    "model.eval().cuda()\n",
    "\n",
    "with  torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Make predictions.\n",
    "        prediction = model(inputs)\n",
    "\n",
    "        # Retrieve predictions indexes.\n",
    "        _, predicted_class = torch.max(prediction.data, 1)\n",
    "\n",
    "        # Compute number of correct predictions.\n",
    "        correct += (predicted_class == labels).float().sum().item()\n",
    "\n",
    "test_accuracy = correct / test_samples_num\n",
    "print('Test accuracy: {}'.format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval().to(device)\n",
    "predictions = []\n",
    "ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, batch_ids in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        ids.extend(batch_ids.numpy())\n",
    "\n",
    "# Create DataFrame and save as CSV\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'ID': ids, 'Labels': predictions})\n",
    "df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission CSV saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
