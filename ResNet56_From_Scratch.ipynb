{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g7Qx3Sb7-tD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mPnawhC7-tF",
        "outputId": "646b4228-0910-48d0-c56a-e0cf599b801b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZL8T3Do8J5s",
        "outputId": "6b97faf1-f332-4c6a-ca3d-990a6ea0a362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar  2 20:46:16 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwngtd6i7-tL"
      },
      "outputs": [],
      "source": [
        "class LambdaLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    This class defines a Lambda Layer. It allows to perform arbitrary operations specified by the \"lambd\" argument.\n",
        "\n",
        "    Attributes:\n",
        "        lambd: a function that defines the operation to be performed on the input.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lambd):\n",
        "        \"\"\"\n",
        "        Init method for the Lambda Layer.\n",
        "\n",
        "        Args:\n",
        "            lambd (function): Function that defines the operation to be performed on the input.\n",
        "        \"\"\"\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Lambda Layer. It applies the function to the input.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor to the Lambda Layer.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output of the Lambda Layer after applying the function.\n",
        "        \"\"\"\n",
        "        return self.lambd(x)\n",
        "\n",
        "class BasicConvBlock(nn.Module):\n",
        "\n",
        "    ''' The BasicConvBlock takes an input with in_channels, applies some blocks of convolutional layers\n",
        "    to reduce it to out_channels and sum it up to the original input.\n",
        "    If their sizes mismatch, then the input goes into an identity.\n",
        "\n",
        "    Basically The BasicConvBlock will implement the regular basic Conv Block +\n",
        "    the shortcut block that does the dimension matching job (option A or B) when dimension changes between 2 blocks\n",
        "    '''\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, option='A'):\n",
        "        \"\"\"\n",
        "        Init method for the Basic Convolution Block.\n",
        "\n",
        "        Args:\n",
        "            in_channels (int): Number of channels in the input tensor.\n",
        "            out_channels (int): Number of channels in the output tensor.\n",
        "            stride (int, optional): Stride for the convolution operation. Default is 1.\n",
        "            option (str, optional): Option for the shortcut connection to match dimensions. Default is 'A'.\n",
        "        \"\"\"\n",
        "        super(BasicConvBlock, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv1', nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)),\n",
        "            ('bn1', nn.BatchNorm2d(out_channels)),\n",
        "            ('act1', nn.ReLU()),\n",
        "            ('conv2', nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "            ('bn2', nn.BatchNorm2d(out_channels))\n",
        "        ]))\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        '''  When input and output spatial dimensions don't match, we have 2 options, with stride:\n",
        "            - A) Use identity shortcuts with zero padding to increase channel dimension.\n",
        "            - B) Use 1x1 convolution to increase channel dimension (projection shortcut).\n",
        "         '''\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            if option == 'A':\n",
        "                # Use identity shortcuts with zero padding to increase channel dimension.\n",
        "                pad_to_add = out_channels//4\n",
        "                ''' ::2 is doing the job of stride = 2\n",
        "                F.pad apply padding to (W,H,C,N).\n",
        "\n",
        "                The padding lengths are specified in reverse order of the dimensions,\n",
        "                F.pad(x[:, :, ::2, ::2], (0,0, 0,0, pad,pad, 0,0))\n",
        "\n",
        "                [width_beginning, width_end, height_beginning, height_end, channel_beginning, channel_end, batchLength_beginning, batchLength_end ]\n",
        "\n",
        "                '''\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                            F.pad(x[:, :, ::2, ::2], (0,0, 0,0, pad_to_add, pad_to_add, 0,0)))\n",
        "            if option == 'B':\n",
        "                self.shortcut = nn.Sequential(OrderedDict([\n",
        "                    ('s_conv1', nn.Conv2d(in_channels, 2*out_channels, kernel_size=1, stride=stride, padding=0, bias=False)),\n",
        "                    ('s_bn1', nn.BatchNorm2d(2*out_channels))\n",
        "                ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Basic Convolution Block. It applies the sequence of layers and adds the shortcut connection.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor to the Basic Convolution Block.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output of the Basic Convolution Block.\n",
        "        \"\"\"\n",
        "        out = self.features(x)\n",
        "        # sum it up with shortcut layer\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L7Wn3rkDGwO"
      },
      "source": [
        "\n",
        "\n",
        "### Explanations on using Option A and B in below code\n",
        "\n",
        "```py\n",
        "\n",
        "if stride != 1 or in_channels != out_channels:\n",
        "            if option == 'A':\n",
        "                pad = out_channels//4\n",
        "                # ::2 replace the stride 2 + F.pad apply padding to (W,H,C,N).\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                            F.pad(x[:, :, ::2, ::2], (0,0, 0,0, pad,pad, 0,0)))\n",
        "            if option == 'B':\n",
        "                self.shortcut = nn.Sequential(OrderedDict([\n",
        "                    ('s_conv1', nn.Conv2d(in_channels, 2*out_channels, kernel_size=1, stride=stride, padding=0, bias=False)),\n",
        "                    ('s_bn1', nn.BatchNorm2d(2*out_channels))\n",
        "                ]))\n",
        "\n",
        "```\n",
        "\n",
        "As per the original Paper\n",
        "\n",
        "#### We use identity shortcuts when input and output channel dimensions are the same.\n",
        "\n",
        "#### Otherwise, When input and output spatial dimensions don't match, we have 2 options, with stride:\n",
        "\n",
        "    - A) Use identity shortcuts with zero padding to increase channel dimension.\n",
        "\n",
        "    - B) Use 1x1 convolution to increase channel dimension (projection shortcut).\n",
        "\n",
        "-----------------------\n",
        "\n",
        "### Understanding `F.pad` on a 4-D Tensor and the following line\n",
        "\n",
        "### `F.pad(x[:, :, ::2, ::2], (0,0, 0,0, pad,pad, 0,0)))`\n",
        "\n",
        "https://stackoverflow.com/a/61945903/1902852\n",
        "\n",
        "The padding lengths are specified in reverse order of the dimensions, where every dimension has two values, one for the padding at the beginning and one for the padding at the end.\n",
        "\n",
        "For an image with the dimensions `[channels, height, width]` the padding is given as:\n",
        "\n",
        "`[width_beginning, width_end, height_beginning, height_end, channels_beginning, channels_end]`,\n",
        "\n",
        "which can be reworded to\n",
        "\n",
        "`[left, right, top, bottom]`\n",
        "\n",
        "Therefore the code above pads the images to the right and bottom. The channels are left out, because they are not being padded, which also means that the same padding could be directly applied to the masks.\n",
        "\n",
        "So the below line means\n",
        "\n",
        "`F.pad(x[:, :, ::2, ::2], (0,0, 0,0, pad,pad, 0,0))`\n",
        "\n",
        "\n",
        "`[width_beginning, width_end, height_beginning, height_end, channel_beginning, channel_end, batchLength_beginning, batchLength_end ]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jvgyHXI7-tM"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\" ResNet-56 architecture for CIFAR-10 Dataset of shape 32*32*3.\n",
        "\n",
        "    Args:\n",
        "        block_type (nn.Module): The type of residual block to use.\n",
        "        num_blocks (list): List containing the number of blocks for each layer.\n",
        "\n",
        "    Attributes:\n",
        "        in_channels (int): Number of input channels.\n",
        "        conv0 (nn.Conv2d): Initial convolutional layer.\n",
        "        bn0 (nn.BatchNorm2d): Batch normalization layer.\n",
        "        block1 (nn.Sequential): First block layer.\n",
        "        block2 (nn.Sequential): Second block layer.\n",
        "        block3 (nn.Sequential): Third block layer.\n",
        "        avgpool (nn.AdaptiveAvgPool2d): Adaptive average pooling layer.\n",
        "        linear (nn.Linear): Linear layer for classification. \"\"\"\n",
        "    def __init__(self, block_type, num_blocks):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.in_channels = 32\n",
        "\n",
        "        self.conv0 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn0 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.block1 = self.__build_layer(block_type, 32, num_blocks[0], starting_stride=1)\n",
        "\n",
        "        self.block2 = self.__build_layer(block_type, 64, num_blocks[1], starting_stride=2)\n",
        "\n",
        "        self.block3 = self.__build_layer(block_type, 128, num_blocks[2], starting_stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.linear = nn.Linear(128, 10)\n",
        "\n",
        "    def __build_layer(self, block_type, out_channels, num_blocks, starting_stride):\n",
        "        \"\"\"\n",
        "        Build a layer consisting of multiple residual blocks.\n",
        "\n",
        "        Args:\n",
        "            block_type (nn.Module): The type of residual block to use.\n",
        "            out_channels (int): Number of output channels.\n",
        "            num_blocks (int): Number of blocks in the layer.\n",
        "            starting_stride (int): Stride value for the first block.\n",
        "\n",
        "        Returns:\n",
        "            nn.Sequential: Sequential container of the residual blocks.\n",
        "        \"\"\"\n",
        "\n",
        "        strides_list_for_current_block = [starting_stride] + [1]*(num_blocks-1)\n",
        "        ''' Above line will generate an array whose first element is starting_stride\n",
        "        And it will have (num_blocks-1) more elements each of value 1\n",
        "         '''\n",
        "        # print('strides_list_for_current_block ', strides_list_for_current_block)\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides_list_for_current_block:\n",
        "            layers.append(block_type(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the ResNet model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor.\n",
        "        \"\"\"\n",
        "        out = F.relu(self.bn0(self.conv0(x)))\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TphNtpWQDGwP"
      },
      "source": [
        "### _build_layer() method\n",
        "\n",
        "In ResNet Every layer downsamples the input at the start using stride equals to 2 i.e for 1st convolutional layer in 1st block of a layer.\n",
        "\n",
        "If we look at the first operation of each layer, we see that the stride used at that first one is 2, instead of 1 like for the rest of them.\n",
        "\n",
        "This is because, here in ResNet, reduction between layers is achieved by an increase on the stride, from 1 to 2, at the first convolution of each layer; instead of by a pooling operation, which we are used to see as down samplers.\n",
        "\n",
        "Quoting from Paper\n",
        "\n",
        "\" For both options, when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnvR0RuC7-tN"
      },
      "outputs": [],
      "source": [
        "def ResNet56():\n",
        "    return ResNet(block_type=BasicConvBlock, num_blocks=[12,12,12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47k9cNnn7-tN",
        "outputId": "66543280-45e8-4784-d17f-cb1aaf291885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "            Conv2d-3           [-1, 32, 32, 32]           9,216\n",
            "       BatchNorm2d-4           [-1, 32, 32, 32]              64\n",
            "              ReLU-5           [-1, 32, 32, 32]               0\n",
            "            Conv2d-6           [-1, 32, 32, 32]           9,216\n",
            "       BatchNorm2d-7           [-1, 32, 32, 32]              64\n",
            "    BasicConvBlock-8           [-1, 32, 32, 32]               0\n",
            "            Conv2d-9           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-10           [-1, 32, 32, 32]              64\n",
            "             ReLU-11           [-1, 32, 32, 32]               0\n",
            "           Conv2d-12           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-13           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-14           [-1, 32, 32, 32]               0\n",
            "           Conv2d-15           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-16           [-1, 32, 32, 32]              64\n",
            "             ReLU-17           [-1, 32, 32, 32]               0\n",
            "           Conv2d-18           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-19           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-20           [-1, 32, 32, 32]               0\n",
            "           Conv2d-21           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-22           [-1, 32, 32, 32]              64\n",
            "             ReLU-23           [-1, 32, 32, 32]               0\n",
            "           Conv2d-24           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-25           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-26           [-1, 32, 32, 32]               0\n",
            "           Conv2d-27           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-28           [-1, 32, 32, 32]              64\n",
            "             ReLU-29           [-1, 32, 32, 32]               0\n",
            "           Conv2d-30           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-31           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-32           [-1, 32, 32, 32]               0\n",
            "           Conv2d-33           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-34           [-1, 32, 32, 32]              64\n",
            "             ReLU-35           [-1, 32, 32, 32]               0\n",
            "           Conv2d-36           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-37           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-38           [-1, 32, 32, 32]               0\n",
            "           Conv2d-39           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-40           [-1, 32, 32, 32]              64\n",
            "             ReLU-41           [-1, 32, 32, 32]               0\n",
            "           Conv2d-42           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-43           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-44           [-1, 32, 32, 32]               0\n",
            "           Conv2d-45           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-46           [-1, 32, 32, 32]              64\n",
            "             ReLU-47           [-1, 32, 32, 32]               0\n",
            "           Conv2d-48           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-49           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-50           [-1, 32, 32, 32]               0\n",
            "           Conv2d-51           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-52           [-1, 32, 32, 32]              64\n",
            "             ReLU-53           [-1, 32, 32, 32]               0\n",
            "           Conv2d-54           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-55           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-56           [-1, 32, 32, 32]               0\n",
            "           Conv2d-57           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-58           [-1, 32, 32, 32]              64\n",
            "             ReLU-59           [-1, 32, 32, 32]               0\n",
            "           Conv2d-60           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-61           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-62           [-1, 32, 32, 32]               0\n",
            "           Conv2d-63           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-64           [-1, 32, 32, 32]              64\n",
            "             ReLU-65           [-1, 32, 32, 32]               0\n",
            "           Conv2d-66           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-67           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-68           [-1, 32, 32, 32]               0\n",
            "           Conv2d-69           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-70           [-1, 32, 32, 32]              64\n",
            "             ReLU-71           [-1, 32, 32, 32]               0\n",
            "           Conv2d-72           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-73           [-1, 32, 32, 32]              64\n",
            "   BasicConvBlock-74           [-1, 32, 32, 32]               0\n",
            "           Conv2d-75           [-1, 64, 16, 16]          18,432\n",
            "      BatchNorm2d-76           [-1, 64, 16, 16]             128\n",
            "             ReLU-77           [-1, 64, 16, 16]               0\n",
            "           Conv2d-78           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-79           [-1, 64, 16, 16]             128\n",
            "      LambdaLayer-80           [-1, 64, 16, 16]               0\n",
            "   BasicConvBlock-81           [-1, 64, 16, 16]               0\n",
            "           Conv2d-82           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-83           [-1, 64, 16, 16]             128\n",
            "             ReLU-84           [-1, 64, 16, 16]               0\n",
            "           Conv2d-85           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-86           [-1, 64, 16, 16]             128\n",
            "   BasicConvBlock-87           [-1, 64, 16, 16]               0\n",
            "           Conv2d-88           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-89           [-1, 64, 16, 16]             128\n",
            "             ReLU-90           [-1, 64, 16, 16]               0\n",
            "           Conv2d-91           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-92           [-1, 64, 16, 16]             128\n",
            "   BasicConvBlock-93           [-1, 64, 16, 16]               0\n",
            "           Conv2d-94           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-95           [-1, 64, 16, 16]             128\n",
            "             ReLU-96           [-1, 64, 16, 16]               0\n",
            "           Conv2d-97           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-98           [-1, 64, 16, 16]             128\n",
            "   BasicConvBlock-99           [-1, 64, 16, 16]               0\n",
            "          Conv2d-100           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-101           [-1, 64, 16, 16]             128\n",
            "            ReLU-102           [-1, 64, 16, 16]               0\n",
            "          Conv2d-103           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-104           [-1, 64, 16, 16]             128\n",
            "  BasicConvBlock-105           [-1, 64, 16, 16]               0\n",
            "          Conv2d-106           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-107           [-1, 64, 16, 16]             128\n",
            "            ReLU-108           [-1, 64, 16, 16]               0\n",
            "          Conv2d-109           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-110           [-1, 64, 16, 16]             128\n",
            "  BasicConvBlock-111           [-1, 64, 16, 16]               0\n",
            "          Conv2d-112           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-113           [-1, 64, 16, 16]             128\n",
            "            ReLU-114           [-1, 64, 16, 16]               0\n",
            "          Conv2d-115           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-116           [-1, 64, 16, 16]             128\n",
            "  BasicConvBlock-117           [-1, 64, 16, 16]               0\n",
            "          Conv2d-118           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-119           [-1, 64, 16, 16]             128\n",
            "            ReLU-120           [-1, 64, 16, 16]               0\n",
            "          Conv2d-121           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-122           [-1, 64, 16, 16]             128\n",
            "  BasicConvBlock-123           [-1, 64, 16, 16]               0\n",
            "          Conv2d-124           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-125           [-1, 64, 16, 16]             128\n",
            "            ReLU-126           [-1, 64, 16, 16]               0\n",
            "          Conv2d-127           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-128           [-1, 64, 16, 16]             128\n",
            "  BasicConvBlock-129           [-1, 64, 16, 16]               0\n",
            "          Conv2d-130           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-131           [-1, 64, 16, 16]             128\n",
            "            ReLU-132           [-1, 64, 16, 16]               0\n",
            "          Conv2d-133           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-134           [-1, 64, 16, 16]             128\n",
            "  BasicConvBlock-135           [-1, 64, 16, 16]               0\n",
            "          Conv2d-136           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-137           [-1, 64, 16, 16]             128\n",
            "            ReLU-138           [-1, 64, 16, 16]               0\n",
            "          Conv2d-139           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-140           [-1, 64, 16, 16]             128\n",
            "  BasicConvBlock-141           [-1, 64, 16, 16]               0\n",
            "          Conv2d-142           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-143           [-1, 64, 16, 16]             128\n",
            "            ReLU-144           [-1, 64, 16, 16]               0\n",
            "          Conv2d-145           [-1, 64, 16, 16]          36,864\n",
            "     BatchNorm2d-146           [-1, 64, 16, 16]             128\n",
            "  BasicConvBlock-147           [-1, 64, 16, 16]               0\n",
            "          Conv2d-148            [-1, 128, 8, 8]          73,728\n",
            "     BatchNorm2d-149            [-1, 128, 8, 8]             256\n",
            "            ReLU-150            [-1, 128, 8, 8]               0\n",
            "          Conv2d-151            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-152            [-1, 128, 8, 8]             256\n",
            "     LambdaLayer-153            [-1, 128, 8, 8]               0\n",
            "  BasicConvBlock-154            [-1, 128, 8, 8]               0\n",
            "          Conv2d-155            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-156            [-1, 128, 8, 8]             256\n",
            "            ReLU-157            [-1, 128, 8, 8]               0\n",
            "          Conv2d-158            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-159            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-160            [-1, 128, 8, 8]               0\n",
            "          Conv2d-161            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-162            [-1, 128, 8, 8]             256\n",
            "            ReLU-163            [-1, 128, 8, 8]               0\n",
            "          Conv2d-164            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-165            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-166            [-1, 128, 8, 8]               0\n",
            "          Conv2d-167            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-168            [-1, 128, 8, 8]             256\n",
            "            ReLU-169            [-1, 128, 8, 8]               0\n",
            "          Conv2d-170            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-171            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-172            [-1, 128, 8, 8]               0\n",
            "          Conv2d-173            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-174            [-1, 128, 8, 8]             256\n",
            "            ReLU-175            [-1, 128, 8, 8]               0\n",
            "          Conv2d-176            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-177            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-178            [-1, 128, 8, 8]               0\n",
            "          Conv2d-179            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-180            [-1, 128, 8, 8]             256\n",
            "            ReLU-181            [-1, 128, 8, 8]               0\n",
            "          Conv2d-182            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-183            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-184            [-1, 128, 8, 8]               0\n",
            "          Conv2d-185            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-186            [-1, 128, 8, 8]             256\n",
            "            ReLU-187            [-1, 128, 8, 8]               0\n",
            "          Conv2d-188            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-189            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-190            [-1, 128, 8, 8]               0\n",
            "          Conv2d-191            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-192            [-1, 128, 8, 8]             256\n",
            "            ReLU-193            [-1, 128, 8, 8]               0\n",
            "          Conv2d-194            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-195            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-196            [-1, 128, 8, 8]               0\n",
            "          Conv2d-197            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-198            [-1, 128, 8, 8]             256\n",
            "            ReLU-199            [-1, 128, 8, 8]               0\n",
            "          Conv2d-200            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-201            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-202            [-1, 128, 8, 8]               0\n",
            "          Conv2d-203            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-204            [-1, 128, 8, 8]             256\n",
            "            ReLU-205            [-1, 128, 8, 8]               0\n",
            "          Conv2d-206            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-207            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-208            [-1, 128, 8, 8]               0\n",
            "          Conv2d-209            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-210            [-1, 128, 8, 8]             256\n",
            "            ReLU-211            [-1, 128, 8, 8]               0\n",
            "          Conv2d-212            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-213            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-214            [-1, 128, 8, 8]               0\n",
            "          Conv2d-215            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-216            [-1, 128, 8, 8]             256\n",
            "            ReLU-217            [-1, 128, 8, 8]               0\n",
            "          Conv2d-218            [-1, 128, 8, 8]         147,456\n",
            "     BatchNorm2d-219            [-1, 128, 8, 8]             256\n",
            "  BasicConvBlock-220            [-1, 128, 8, 8]               0\n",
            "AdaptiveAvgPool2d-221            [-1, 128, 1, 1]               0\n",
            "          Linear-222                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 4,565,674\n",
            "Trainable params: 4,565,674\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 32.19\n",
            "Params size (MB): 17.42\n",
            "Estimated Total Size (MB): 49.62\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = ResNet56()\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# device = 'cpu'\n",
        "model.to(device)\n",
        "summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjPLm6BENFbq"
      },
      "source": [
        "## Loading CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us3eora2NFbs"
      },
      "outputs": [],
      "source": [
        "def dataloader_cifar():\n",
        "    \"\"\"\n",
        "    Create dataloaders for the CIFAR-10 dataset.\n",
        "\n",
        "    Returns:\n",
        "        train_loader (torch.utils.data.DataLoader): Dataloader for the training set.\n",
        "        val_loader (torch.utils.data.DataLoader): Dataloader for the validation set.\n",
        "        test_loader (torch.utils.data.DataLoader): Dataloader for the test set.\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.5], std=[0.5])])\n",
        "\n",
        "    # Input Data in Local Machine\n",
        "    # train_dataset = datasets.CIFAR10('../input_data', train=True, download=True, transform=transform)\n",
        "    # test_dataset = datasets.CIFAR10('../input_data', train=False, download=True, transform=transform)\n",
        "\n",
        "    # Input Data in Google Drive\n",
        "    train_dataset = datasets.CIFAR10('/content/drive/MyDrive/All_Datasets/CIFAR10', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.CIFAR10('/content/drive/MyDrive/All_Datasets/CIFAR10', train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split dataset into training set and validation set.\n",
        "    train_dataset, val_dataset = random_split(train_dataset, (45000, 5000))\n",
        "\n",
        "    print(\"Image shape of a random sample image : {}\".format(train_dataset[0][0].numpy().shape), end = '\\n\\n')\n",
        "\n",
        "    print(\"Training Set:   {} images\".format(len(train_dataset)))\n",
        "    print(\"Validation Set:   {} images\".format(len(val_dataset)))\n",
        "    print(\"Test Set:       {} images\".format(len(test_dataset)))\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    # Generate dataloader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E--f56MNFbs",
        "outputId": "eaa5d3fe-7a93-42d4-8996-a85a5fa2ca8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Image shape of a random sample image : (3, 32, 32)\n",
            "\n",
            "Training Set:   45000 images\n",
            "Validation Set:   5000 images\n",
            "Test Set:       10000 images\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader = dataloader_cifar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOv_8vpcNFbt"
      },
      "source": [
        "## Start Actual Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICxcakbK8DRP"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60], gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB_vMJgl8Ei5"
      },
      "outputs": [],
      "source": [
        "def train_model():\n",
        "    EPOCHS = 25\n",
        "    train_samples_num = 45000\n",
        "    val_samples_num = 5000\n",
        "    train_costs, val_costs = [], []\n",
        "\n",
        "    #Training phase.\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        train_running_loss = 0\n",
        "        correct_train = 0\n",
        "\n",
        "        model.train().cuda()\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            \"\"\" for every mini-batch during the training phase, we typically want to explicitly set the gradients\n",
        "            to zero before starting to do backpropragation \"\"\"\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Start the forward pass\n",
        "            prediction = model(inputs)\n",
        "\n",
        "            loss = criterion(prediction, labels)\n",
        "\n",
        "            # do backpropagation and update weights with step()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print('outputs on which to apply torch.max ', prediction)\n",
        "            # find the maximum along the rows, use dim=1 to torch.max()\n",
        "            _, predicted_outputs = torch.max(prediction.data, 1)\n",
        "\n",
        "            # Update the running corrects\n",
        "            correct_train += (predicted_outputs == labels).float().sum().item()\n",
        "\n",
        "            ''' Compute batch loss\n",
        "            multiply each average batch loss with batch-length.\n",
        "            The batch-length is inputs.size(0) which gives the number total images in each batch.\n",
        "            Essentially I am un-averaging the previously calculated Loss '''\n",
        "            train_running_loss += (loss.data.item() * inputs.shape[0])\n",
        "\n",
        "\n",
        "        train_epoch_loss = train_running_loss / train_samples_num\n",
        "\n",
        "        train_costs.append(train_epoch_loss)\n",
        "\n",
        "        train_acc =  correct_train / train_samples_num\n",
        "\n",
        "        # Now check trained weights on the validation set\n",
        "        val_running_loss = 0\n",
        "        correct_val = 0\n",
        "\n",
        "        model.eval().cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass.\n",
        "                prediction = model(inputs)\n",
        "\n",
        "                # Compute the loss.\n",
        "                loss = criterion(prediction, labels)\n",
        "\n",
        "                # Compute validation accuracy.\n",
        "                _, predicted_outputs = torch.max(prediction.data, 1)\n",
        "                correct_val += (predicted_outputs == labels).float().sum().item()\n",
        "\n",
        "            # Compute batch loss.\n",
        "            val_running_loss += (loss.data.item() * inputs.shape[0])\n",
        "\n",
        "            val_epoch_loss = val_running_loss / val_samples_num\n",
        "            val_costs.append(val_epoch_loss)\n",
        "            val_acc =  correct_val / val_samples_num\n",
        "\n",
        "        info = \"[Epoch {}/{}]: train-loss = {:0.6f} | train-acc = {:0.3f} | val-loss = {:0.6f} | val-acc = {:0.3f}\"\n",
        "\n",
        "        print(info.format(epoch+1, EPOCHS, train_epoch_loss, train_acc, val_epoch_loss, val_acc))\n",
        "\n",
        "        torch.save(model.state_dict(), '/content/checkpoint_gpu_{}'.format(epoch + 1))\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/resnet-56_weights_gpu')\n",
        "\n",
        "    return train_costs, val_costs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJaEBgbt9INy",
        "outputId": "951df6cd-f10a-4640-8210-20332eac9c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/25]: train-loss = 0.470197 | train-acc = 0.837 | val-loss = 0.000912 | val-acc = 0.749\n",
            "[Epoch 2/25]: train-loss = 0.386259 | train-acc = 0.867 | val-loss = 0.002649 | val-acc = 0.780\n",
            "[Epoch 3/25]: train-loss = 0.317335 | train-acc = 0.888 | val-loss = 0.000544 | val-acc = 0.745\n",
            "[Epoch 4/25]: train-loss = 0.244087 | train-acc = 0.914 | val-loss = 0.000928 | val-acc = 0.754\n",
            "[Epoch 5/25]: train-loss = 0.199033 | train-acc = 0.929 | val-loss = 0.001656 | val-acc = 0.787\n",
            "[Epoch 6/25]: train-loss = 0.161549 | train-acc = 0.943 | val-loss = 0.002023 | val-acc = 0.759\n",
            "[Epoch 7/25]: train-loss = 0.135564 | train-acc = 0.953 | val-loss = 0.001688 | val-acc = 0.787\n",
            "[Epoch 8/25]: train-loss = 0.110733 | train-acc = 0.961 | val-loss = 0.002326 | val-acc = 0.780\n",
            "[Epoch 9/25]: train-loss = 0.098684 | train-acc = 0.965 | val-loss = 0.005426 | val-acc = 0.797\n",
            "[Epoch 10/25]: train-loss = 0.072463 | train-acc = 0.975 | val-loss = 0.001094 | val-acc = 0.790\n",
            "[Epoch 11/25]: train-loss = 0.059941 | train-acc = 0.979 | val-loss = 0.000290 | val-acc = 0.793\n",
            "[Epoch 12/25]: train-loss = 0.053645 | train-acc = 0.982 | val-loss = 0.003593 | val-acc = 0.795\n",
            "[Epoch 13/25]: train-loss = 0.052836 | train-acc = 0.982 | val-loss = 0.000741 | val-acc = 0.787\n",
            "[Epoch 14/25]: train-loss = 0.056149 | train-acc = 0.980 | val-loss = 0.002175 | val-acc = 0.796\n",
            "[Epoch 15/25]: train-loss = 0.040668 | train-acc = 0.986 | val-loss = 0.003542 | val-acc = 0.806\n",
            "[Epoch 16/25]: train-loss = 0.034979 | train-acc = 0.988 | val-loss = 0.001214 | val-acc = 0.784\n",
            "[Epoch 17/25]: train-loss = 0.033960 | train-acc = 0.989 | val-loss = 0.000001 | val-acc = 0.807\n",
            "[Epoch 18/25]: train-loss = 0.030301 | train-acc = 0.990 | val-loss = 0.000066 | val-acc = 0.803\n",
            "[Epoch 19/25]: train-loss = 0.021934 | train-acc = 0.993 | val-loss = 0.000209 | val-acc = 0.804\n",
            "[Epoch 20/25]: train-loss = 0.018485 | train-acc = 0.994 | val-loss = 0.002116 | val-acc = 0.806\n",
            "[Epoch 21/25]: train-loss = 0.014837 | train-acc = 0.996 | val-loss = 0.003647 | val-acc = 0.807\n",
            "[Epoch 22/25]: train-loss = 0.016103 | train-acc = 0.995 | val-loss = 0.000007 | val-acc = 0.807\n",
            "[Epoch 23/25]: train-loss = 0.043420 | train-acc = 0.985 | val-loss = 0.004467 | val-acc = 0.796\n",
            "[Epoch 24/25]: train-loss = 0.030503 | train-acc = 0.990 | val-loss = 0.000148 | val-acc = 0.782\n",
            "[Epoch 25/25]: train-loss = 0.021587 | train-acc = 0.993 | val-loss = 0.000589 | val-acc = 0.807\n"
          ]
        }
      ],
      "source": [
        "# !pwd\n",
        "train_costs, val_costs = train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg45TKgb8N0k",
        "outputId": "5c5e69f8-c3f6-4e6a-90b1-2137baee1387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-072f60bf604f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/resnet-56_weights_gpu'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#Restore the model.\n",
        "model = ResNet56()\n",
        "model.load_state_dict(torch.load('/content/resnet-56_weights_gpu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AODk608HNFbv"
      },
      "source": [
        "## Test the trained model on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Inspect the .pkl file structure\n",
        "with open('/content/cifar_test_nolabel.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "    print(\"Keys in .pkl file:\", data.keys())  # For dictionaries\n",
        "    print(\"Type of data:\", type(data))        # For non-dictionary structures\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paOYm5TwtdIl",
        "outputId": "387d30f7-f3d0-4ac3-d65d-dc2119c92d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in .pkl file: dict_keys([b'data', b'ids'])\n",
            "Type of data: <class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPbkor1g8Q3r"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomTestDataset(Dataset):\n",
        "    def __init__(self, pkl_path, transform=None):\n",
        "        with open(pkl_path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        # Access keys as byte strings (b'...')\n",
        "        self.ids = data[b'ids']             # IDs from the .pkl file\n",
        "        self.images = data[b'data']         # Image data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # CIFAR-10 images are stored as (3072,) flat arrays; reshape to 32x32x3\n",
        "        image = self.images[idx].reshape(3, 32, 32).transpose(1, 2, 0)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.ids[idx]\n",
        "\n",
        "# Use the same transforms as training (3-channel normalization)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load custom dataset\n",
        "custom_dataset = CustomTestDataset('/content/cifar_test_nolabel.pkl', transform=transform)\n",
        "test_loader = DataLoader(custom_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval().cuda()\n",
        "all_ids = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, ids in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_ids.extend(ids.cpu().numpy())  # Convert byte IDs to integers if needed\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# Save to CSV\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'ID': all_ids, 'Labels': all_preds})\n",
        "df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "59K_DN1ft7yE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}